{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is to detect and replace the values of any loss of data\n",
    "\n",
    "## Sensor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two types of outliers in out dataset, missing data aka NaN or data putted as 0.\n",
    "For both temperatures, it's pretty straightforwards because the temps never goes below 20 degrees (roughly), so detecting missing values is easy.\n",
    "\n",
    "But for irradiation, we have to detect where values at 0 shouldn't be there.\n",
    "\n",
    "UPDDATE 1: Noticed that I was wrong, no real value at 0 but lots of missing values, not NaN but missing, so need to remake the dataset to add those dates and times at those points.\n",
    "\n",
    "To do that, we'll \"split\" the dataset use Kmeans clustering, and detect all values at 0 in the middle of the day.\n",
    "\n",
    "Afterwards, we'll be using the \"cleaned\" set to apply feature engineering for each columns, and finally chose, train and use a model to replace each missing/wrong values\n",
    "\n",
    "Finally, we'll save the new dataset as parquet file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import *\n",
    "from src.feature_engineering import *\n",
    "# Load both training and dataset used for end completion. \n",
    "dfs = load_sensor(\"dataset/Plant_1_Weather_Sensor_Data.csv\", save=False)\n",
    "# Get the X and y for all expectedd values\n",
    "irr_X, irr_y = sensor_for_irradiation(dfs[0])\n",
    "atemp_X, atemp_y = sensor_for_ambient_temp(dfs[0])\n",
    "mtemp_X, mtemp_y = sensor_for_module_temp(dfs[0])\n",
    "\n",
    "# Now that we have all starting values we take a quick glance at one of them\n",
    "# irr_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRRADIATION (Chosing best models)\n",
    "\n",
    "As suspecting non-linear relationships, I'll focus on those first models to take a grasp of our goals:\n",
    "- SVMs\n",
    "- DecisionTree\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "\n",
    "Additionnal models that can be noted for further tests:\n",
    "- Neural Nets\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "These metrics will be used to get a good overview of models performances on requested tasks:\n",
    "- R-Squared\n",
    "- MAE\n",
    "- MSE\n",
    "- RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 40 candidates, totalling 80 fits\n",
      "{'C': 16, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "-----------SVM-----------\n",
      "r2:0.9570077536976176\n",
      "MAE:0.0392994736688664\n",
      "MSE:0.0036580574443085536\n",
      "RMSE:0.060481876990620534\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "{'criterion': 'squared_error', 'max_depth': 11, 'min_samples_split': 12, 'splitter': 'random'}\n",
      "-----------DT-----------\n",
      "r2:0.9566498064182145\n",
      "MAE:0.030151802033353967\n",
      "MSE:0.003701326460104872\n",
      "RMSE:0.06083852776082663\n",
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 85}\n",
      "-----------RF-----------\n",
      "r2:0.9378672041932105\n",
      "MAE:0.045347806172349986\n",
      "MSE:0.004697701540228066\n",
      "RMSE:0.06853978071330595\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 160, 'subsample': 0.6}\n",
      "-----------GB-----------\n",
      "r2:0.9609380623081305\n",
      "MAE:0.03149596724956426\n",
      "MSE:0.003303391858879091\n",
      "RMSE:0.05747514122539492\n"
     ]
    }
   ],
   "source": [
    "from src.model import * \n",
    "mods = []\n",
    "for m in ['SVM', 'DT', 'RF', 'GB']:\n",
    "    model, metrics = model_testing(irr_X,irr_y, m)\n",
    "    mods.append(mods)\n",
    "    print(f'-----------{m}-----------')\n",
    "    print(f\"r2:{metrics['r2']}\\nMAE:{metrics['MAE']}\\nMSE:{metrics['MSE']}\\nRMSE:{metrics['RMSE']}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without surprise, Gradient boosting is one of the best models and goes toe to toe with randomforest (And slightly better if we take all metrics into consideration).\n",
    "And quite surprisingly, SVM and Decision Tree are also toe-to-toe but on the lower end.\n",
    "\n",
    "Now we'll try out adding some shallow tuning to see if there's any differences.\n",
    "\n",
    "**UPDATE 1:**\n",
    "Has it look like the computation time for my grids are way too high, reason are combination of many possibilities AND numbers are too high.\n",
    "\n",
    "**Example with SVR**: Computing C as 100 is twice or even thrices the computing time of 50.\n",
    "\n",
    "SO i'm putting my expectations way down to get a first line of sight of the parameters and improvement I could do.\n",
    "For some example of computations time tested (SO far for SVR (sight)) are twice 800 mins and one 1200, each reviewing the grid by nearly halfing it.\n",
    "\n",
    "**UPDATE 2:**\n",
    "The SVR computationnal issue was situated on the fact that a poly kernel doesn't fit well with gamma (need to expand on why exactly though)\n",
    "This was taking ages for nothings.\n",
    "Now should be resolved.|\n",
    "\n",
    "**UPDATE 3:**\n",
    "\n",
    "After simple tuning, we can bost SVM & DT to a way better fitting, for them to be closer to GB & RF.\n",
    "On the other hands, parameters used for fitting RF are not sufficient or too shallow, hence giving an overall worse prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 2545, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.231840\n",
      "0\n",
      "0.9496143796207761\n",
      "0.03206345258992144\n",
      "0.004268907342379536\n",
      "0.0653368758235312\n",
      "1\n",
      "0.9588535545223675\n",
      "0.029951370402308206\n",
      "0.0034899367212076105\n",
      "0.05907568637948789\n",
      "2\n",
      "0.8959211544851708\n",
      "0.0754630963298425\n",
      "0.009671767996022507\n",
      "0.09834514729269822\n"
     ]
    }
   ],
   "source": [
    "# Trying out other libraries' \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(irr_X, irr_y, test_size=0.2, random_state=42)\n",
    "extreme = xgb.XGBRegressor()\n",
    "light = lgb.LGBMRegressor()\n",
    "percep = MLPRegressor()\n",
    "\n",
    "extreme.fit(x_train, y_train)\n",
    "light.fit(x_train, y_train)\n",
    "percep.fit(x_train, y_train)\n",
    "\n",
    "preds  = []\n",
    "preds.append(extreme.predict(x_dev))\n",
    "preds.append(light.predict(x_dev))\n",
    "preds.append(percep.predict(x_dev))\n",
    "\n",
    "for index, p in enumerate(preds):\n",
    "    print(index)\n",
    "    print(r2_score(p, y_dev))\n",
    "    print(mean_absolute_error(p, y_dev))\n",
    "    print(mean_squared_error(p, y_dev, squared=True))\n",
    "    print(mean_squared_error(p, y_dev, squared=False))\n",
    "\n",
    "# Finishing by deeply tuning the expected candidate for best fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Plain lightgbm is working nearly as well as shallow tuned GB\n",
    "\n",
    "#### End Tuning\n",
    "\n",
    "For finishing the full tuning process I'll be using bayesian optimization technique as a part of the last parameter tuning.\n",
    "\n",
    "Will do it for Common Gradient Boosting and LightGBM as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing & Displaying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing if getting the same values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
